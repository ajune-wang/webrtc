{
  "comments": [
    {
      "key": {
        "uuid": "9e217a5d_a1ee0da2",
        "filename": "api/video/video_frame.h",
        "patchSetId": 3
      },
      "lineNbr": 36,
      "author": {
        "id": 5234
      },
      "writtenOn": "2019-01-30T11:03:55Z",
      "side": 1,
      "message": "Still unclear why these are needed. Can you explain?\n\nIf they ever differ from the dimension of of the previous frame, there will be a problem.",
      "range": {
        "startLine": 34,
        "startChar": 0,
        "endLine": 36,
        "endChar": 20
      },
      "revId": "3562f7d876c61f62404f6c7f13e54d37043fc794",
      "serverId": "58829da1-049c-39fb-b951-ebdcd0984767",
      "unresolved": true
    },
    {
      "key": {
        "uuid": "22abe696_9a940172",
        "filename": "api/video/video_frame.h",
        "patchSetId": 3
      },
      "lineNbr": 36,
      "author": {
        "id": 5117
      },
      "writtenOn": "2019-01-30T11:50:55Z",
      "side": 1,
      "message": "Yes, there will be a problem and it\u0027s handled correctly in the following CLs. But to be even able to detect this problem we include these fields.\n\nE.g. if we omit them, we can\u0027t detect a bad user, who sents a partial update after the resolution have changed",
      "parentUuid": "9e217a5d_a1ee0da2",
      "range": {
        "startLine": 34,
        "startChar": 0,
        "endLine": 36,
        "endChar": 20
      },
      "revId": "3562f7d876c61f62404f6c7f13e54d37043fc794",
      "serverId": "58829da1-049c-39fb-b951-ebdcd0984767",
      "unresolved": true
    },
    {
      "key": {
        "uuid": "6bb5ac34_a6d95e0e",
        "filename": "api/video/video_frame.h",
        "patchSetId": 3
      },
      "lineNbr": 36,
      "author": {
        "id": 5234
      },
      "writtenOn": "2019-01-30T12:26:20Z",
      "side": 1,
      "message": "I\u0027m thinking that it\u0027s not worth 8 bytes in this struct, just to detecting bad usage.\n\nDownstream code can just check that the partial frame fits inside the previous frame (it has to do that anyway), and then just paste it at the given position. It\u0027s then the responsibility of the frame source to produce a consistent stream of full and partial frames.\n\nI mean, there are lots of ways a camera or capturer could misbehave, resulting in garbled data; it\u0027s not clear to me why we\u0027d need special handling of this particular way it could possibly misbehave.",
      "parentUuid": "22abe696_9a940172",
      "range": {
        "startLine": 34,
        "startChar": 0,
        "endLine": 36,
        "endChar": 20
      },
      "revId": "3562f7d876c61f62404f6c7f13e54d37043fc794",
      "serverId": "58829da1-049c-39fb-b951-ebdcd0984767",
      "unresolved": true
    },
    {
      "key": {
        "uuid": "bacc977c_dc6585b4",
        "filename": "api/video/video_frame.h",
        "patchSetId": 3
      },
      "lineNbr": 36,
      "author": {
        "id": 5117
      },
      "writtenOn": "2019-01-30T12:45:23Z",
      "side": 1,
      "message": "Sorry,I didn\u0027t mention the main reason for these fields. We need to somehow notify the webrtc that the frame is the full frame.\n\nIdea is that ParitalDescription is an optional field of VideoFrame and normally it\u0027s not set at all and nothing is changed in how WebRTC behaves. But if the field is present, webrtc will cache the last frame to support partial updates and perform them, if needed. This is a necessary and heavy operation, so we want to avoid it in case partial capture is not desired. \n\nThus, the PartialDescription needs some way of showing that the frame is a full picture.\nIt can be just a bool flag, but 8 bytes is nothing compared to a whole uncompressed frame buffer, and it allows to check for possible errors in the capturer at the chrome side.\n\nOther alternative would be to pass some special values as offset (e.g -1), but it seems a bit hacky to me.",
      "parentUuid": "6bb5ac34_a6d95e0e",
      "range": {
        "startLine": 34,
        "startChar": 0,
        "endLine": 36,
        "endChar": 20
      },
      "revId": "3562f7d876c61f62404f6c7f13e54d37043fc794",
      "serverId": "58829da1-049c-39fb-b951-ebdcd0984767",
      "unresolved": true
    },
    {
      "key": {
        "uuid": "1f9a7daf_263c56a2",
        "filename": "api/video/video_frame.h",
        "patchSetId": 3
      },
      "lineNbr": 36,
      "author": {
        "id": 5234
      },
      "writtenOn": "2019-01-30T13:16:34Z",
      "side": 1,
      "message": "\u003e Sorry,I didn\u0027t mention the main reason for these fields. We need to somehow notify the webrtc that the frame is the full frame.\n\u003e \n\u003e Idea is that ParitalDescription is an optional field of VideoFrame and normally it\u0027s not set at all and nothing is changed in how WebRTC behaves. But if the field is present, webrtc will cache the last frame to support partial updates and perform them, if needed. This is a necessary and heavy operation, so we want to avoid it in case partial capture is not desired. \n\nThanks, that makes it a lot clearer. I don\u0027t quite like this way of signalling, though. I\u0027m thinking of alternatives.\n\nFirst, it\u0027s a bit backwards to have the video source tell the encoder to enable a feature. It would fit better with other coordination between sinks and sources to configure the encoder (VideoStreamEncoder level or close to that) to enable support for partial frames, and then let it signal via VideoSinkWants that it is willing to process partial frames.\n  \n\u003e It can be just a bool flag, but 8 bytes is nothing compared to a whole uncompressed frame buffer, and it allows to check for possible errors in the capturer at the chrome side.\n\nIt\u0027s not really the allocation cost I\u0027m concerned with, but copying overhead. VideoFrameBuffer is large, and always passed by reference. While VideoFrame, on the other hand, is copied in a lot of places.\n\nAs for the cost of the cache of the last frame, it might well be workable to always keep a reference to the last frame buffer (frame buffers are reference counted, so no copy needed, it only extends the lifetime of the buffer a little. And we\u0027d probably can\u0027t do it for texture frames (see handling of pending_frame_ in VideoStreamEncoder)).\n\nOnly when we see the first partial frame, we need to allocate a copy of the last frame to use as a canvas.\n\nThe same reference to last frame could be reused to implement the feature related to the |changed()| flag.",
      "parentUuid": "bacc977c_dc6585b4",
      "range": {
        "startLine": 34,
        "startChar": 0,
        "endLine": 36,
        "endChar": 20
      },
      "revId": "3562f7d876c61f62404f6c7f13e54d37043fc794",
      "serverId": "58829da1-049c-39fb-b951-ebdcd0984767",
      "unresolved": true
    },
    {
      "key": {
        "uuid": "1166f83c_ea76a195",
        "filename": "api/video/video_frame.h",
        "patchSetId": 3
      },
      "lineNbr": 36,
      "author": {
        "id": 5117
      },
      "writtenOn": "2019-01-30T13:30:05Z",
      "side": 1,
      "message": "\u003e First, it\u0027s a bit backwards to have the video source tell the encoder to enable a feature.\n\nBut it\u0027s the capturer feature. The capturer decides to do this, not all capturers would even be able to do it. Encoder doesn\u0027t know anything about partial frames, it always receives a full resolution frame (maybe marked as unchanged in the future). So, idea is that in WebRTC we can process these special partial frames if someone produces them.\n\n\u003e Only when we see the first partial frame, we need to allocate a copy of the last frame to use as a canvas.\n\nEven if we just keep the reference to the last full frame, it means the the extra buffer will be living all the time, which is additional memory. \n\n\u003e It\u0027s not really the allocation cost I\u0027m concerned with, but copying overhead. VideoFrameBuffer is large, and always passed by reference. While VideoFrame, on the other hand, is copied in a lot of places.\n\nThis optional structure should never be copied. It should be consumed at the very moment WebRTC receives the frame.",
      "parentUuid": "1f9a7daf_263c56a2",
      "range": {
        "startLine": 34,
        "startChar": 0,
        "endLine": 36,
        "endChar": 20
      },
      "revId": "3562f7d876c61f62404f6c7f13e54d37043fc794",
      "serverId": "58829da1-049c-39fb-b951-ebdcd0984767",
      "unresolved": true
    },
    {
      "key": {
        "uuid": "12b8417f_7fa96ec9",
        "filename": "api/video/video_frame.h",
        "patchSetId": 3
      },
      "lineNbr": 36,
      "author": {
        "id": 5234
      },
      "writtenOn": "2019-01-30T13:45:09Z",
      "side": 1,
      "message": "\u003e But it\u0027s the capturer feature. The capturer decides to do this, not all capturers would even be able to do it. Encoder doesn\u0027t know anything about partial frames, it always receives a full resolution frame (maybe marked as unchanged in the future). So, idea is that in WebRTC we can process these special partial frames if someone produces them.\n\nNow I\u0027m getting confused. First, not all sinks can be expected to understand partial frames (e.g., local renderer). Which is why VideoSinkWants signalling seems reasonable.\n\nSecond, if it is a capturer feature, why expose partial frames at all to the pipeline downstream from the capturer?\n \n\u003e This optional structure should never be copied. It should be consumed at the very moment WebRTC receives the frame.\n\nVideoFrame can be passed by value, which implies copying. But maybe that\u0027s less common than I thought.",
      "parentUuid": "1166f83c_ea76a195",
      "range": {
        "startLine": 34,
        "startChar": 0,
        "endLine": 36,
        "endChar": 20
      },
      "revId": "3562f7d876c61f62404f6c7f13e54d37043fc794",
      "serverId": "58829da1-049c-39fb-b951-ebdcd0984767",
      "unresolved": true
    },
    {
      "key": {
        "uuid": "3010ccf7_b51a5fff",
        "filename": "api/video/video_frame.h",
        "patchSetId": 3
      },
      "lineNbr": 36,
      "author": {
        "id": 5117
      },
      "writtenOn": "2019-01-30T14:30:13Z",
      "side": 1,
      "message": "Removed full_widht and full_height.",
      "parentUuid": "12b8417f_7fa96ec9",
      "range": {
        "startLine": 34,
        "startChar": 0,
        "endLine": 36,
        "endChar": 20
      },
      "revId": "3562f7d876c61f62404f6c7f13e54d37043fc794",
      "serverId": "58829da1-049c-39fb-b951-ebdcd0984767",
      "unresolved": false
    }
  ]
}