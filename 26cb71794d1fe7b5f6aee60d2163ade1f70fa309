{
  "comments": [
    {
      "key": {
        "uuid": "33dcdd2b_5f12fe54",
        "filename": "/PATCHSET_LEVEL",
        "patchSetId": 2
      },
      "lineNbr": 0,
      "author": {
        "id": 5527
      },
      "writtenOn": "2020-09-10T11:41:22Z",
      "side": 1,
      "message": "Nisse, PTAL",
      "revId": "26cb71794d1fe7b5f6aee60d2163ade1f70fa309",
      "serverId": "58829da1-049c-39fb-b951-ebdcd0984767",
      "unresolved": false
    },
    {
      "key": {
        "uuid": "ee670eff_61add130",
        "filename": "/PATCHSET_LEVEL",
        "patchSetId": 2
      },
      "lineNbr": 0,
      "author": {
        "id": 5234
      },
      "writtenOn": "2020-09-10T12:46:05Z",
      "side": 1,
      "message": "One main question on the design.",
      "revId": "26cb71794d1fe7b5f6aee60d2163ade1f70fa309",
      "serverId": "58829da1-049c-39fb-b951-ebdcd0984767",
      "unresolved": false
    },
    {
      "key": {
        "uuid": "bc0ca38b_2f886aaf",
        "filename": "api/video/video_stream_decoder.h",
        "patchSetId": 2
      },
      "lineNbr": 33,
      "author": {
        "id": 5234
      },
      "writtenOn": "2020-09-10T12:46:05Z",
      "side": 1,
      "message": "Maybe shorten to just \"FrameInfo\"?",
      "range": {
        "startLine": 33,
        "startChar": 11,
        "endLine": 33,
        "endChar": 24
      },
      "revId": "26cb71794d1fe7b5f6aee60d2163ade1f70fa309",
      "serverId": "58829da1-049c-39fb-b951-ebdcd0984767",
      "unresolved": true
    },
    {
      "key": {
        "uuid": "be8bf7c3_467f7ecb",
        "filename": "api/video/video_stream_decoder.h",
        "patchSetId": 2
      },
      "lineNbr": 33,
      "author": {
        "id": 5527
      },
      "writtenOn": "2020-09-10T13:35:34Z",
      "side": 1,
      "message": "Done",
      "parentUuid": "bc0ca38b_2f886aaf",
      "range": {
        "startLine": 33,
        "startChar": 11,
        "endLine": 33,
        "endChar": 24
      },
      "revId": "26cb71794d1fe7b5f6aee60d2163ade1f70fa309",
      "serverId": "58829da1-049c-39fb-b951-ebdcd0984767",
      "unresolved": false
    },
    {
      "key": {
        "uuid": "c2cca18b_302c8e9e",
        "filename": "api/video/video_stream_decoder.h",
        "patchSetId": 2
      },
      "lineNbr": 36,
      "author": {
        "id": 5234
      },
      "writtenOn": "2020-09-10T12:46:05Z",
      "side": 1,
      "message": "I take it this information arrives on the wire?",
      "range": {
        "startLine": 36,
        "startChar": 0,
        "endLine": 36,
        "endChar": 36
      },
      "revId": "26cb71794d1fe7b5f6aee60d2163ade1f70fa309",
      "serverId": "58829da1-049c-39fb-b951-ebdcd0984767",
      "unresolved": true
    },
    {
      "key": {
        "uuid": "283d4d7f_353f76db",
        "filename": "api/video/video_stream_decoder.h",
        "patchSetId": 2
      },
      "lineNbr": 36,
      "author": {
        "id": 5527
      },
      "writtenOn": "2020-09-10T13:35:34Z",
      "side": 1,
      "message": "correct",
      "parentUuid": "c2cca18b_302c8e9e",
      "range": {
        "startLine": 36,
        "startChar": 0,
        "endLine": 36,
        "endChar": 36
      },
      "revId": "26cb71794d1fe7b5f6aee60d2163ade1f70fa309",
      "serverId": "58829da1-049c-39fb-b951-ebdcd0984767",
      "unresolved": false
    },
    {
      "key": {
        "uuid": "09c2f687_94b2155d",
        "filename": "api/video/video_stream_decoder.h",
        "patchSetId": 2
      },
      "lineNbr": 54,
      "author": {
        "id": 5234
      },
      "writtenOn": "2020-09-10T12:46:05Z",
      "side": 1,
      "message": "Is there any good reason to split meta data between VideoFrame and the new struct?\n\nwebrtc::VideoFrame already has a processing_time_ member which appears to have a similar purpose as the decode_time_ms. It would make some sense to add a VideoContentType to VideoFrame. Adding qp would be more questionable.\n\nProper design also depends also a bit on where these values are expected to be consumed. By the direct callee of OnDecodedFrame, or will they be passed on through the pipeline together with the VideoFrame?",
      "range": {
        "startLine": 53,
        "startChar": 31,
        "endLine": 54,
        "endChar": 63
      },
      "revId": "26cb71794d1fe7b5f6aee60d2163ade1f70fa309",
      "serverId": "58829da1-049c-39fb-b951-ebdcd0984767",
      "unresolved": true
    },
    {
      "key": {
        "uuid": "ea256229_e548c922",
        "filename": "api/video/video_stream_decoder.h",
        "patchSetId": 2
      },
      "lineNbr": 54,
      "author": {
        "id": 5527
      },
      "writtenOn": "2020-09-10T13:35:34Z",
      "side": 1,
      "message": "\u003e Is there any good reason to split meta data between VideoFrame and the new struct?\n\nThe initial (current) design of OnDecodedFrame is just a mirroring of the DecodedImageCallback::Decoded callback, now that I added an additional member I though creating a FrameInfo struct was cleaner, can\u0027t say if it\u0027s the better design or not.\n\n\u003e webrtc::VideoFrame already has a processing_time_ member which appears to have a similar purpose as the decode_time_ms. It would make some sense to add a VideoContentType to VideoFrame. Adding qp would be more questionable.\n\nWas not aware of |processing_time_|, it should also be set in the VideoStreamDecoder (but that\u0027s for another CL).\n\n\u003e Proper design also depends also a bit on where these values are expected to be consumed. By the direct callee of OnDecodedFrame, or will they be passed on through the pipeline together with the VideoFrame?\n\nThe VideoContentType does not follow the frame throughout the rest of the pipeline, it goes its own way and is only used to separate video and screenshare metrics.\n\nI think at some point we have to decide if we want a VideoFrame (that represents just the decoded video frame, and timestamp I guess), or an RtcVideoFrame (that contains all kind of information relevant for an RTC system). Maybe the VideoFrameBuffer could already be considered to be the \"VideoFrame\" though...",
      "parentUuid": "09c2f687_94b2155d",
      "range": {
        "startLine": 53,
        "startChar": 31,
        "endLine": 54,
        "endChar": 63
      },
      "revId": "26cb71794d1fe7b5f6aee60d2163ade1f70fa309",
      "serverId": "58829da1-049c-39fb-b951-ebdcd0984767",
      "unresolved": true
    },
    {
      "key": {
        "uuid": "bedce770_ffd3a324",
        "filename": "api/video/video_stream_decoder.h",
        "patchSetId": 2
      },
      "lineNbr": 54,
      "author": {
        "id": 5234
      },
      "writtenOn": "2020-09-10T14:34:27Z",
      "side": 1,
      "message": "\u003e \u003e Is there any good reason to split meta data between VideoFrame and the new struct?\n\u003e \n\u003e The initial (current) design of OnDecodedFrame is just a mirroring of the DecodedImageCallback::Decoded callback, now that I added an additional member I though creating a FrameInfo struct was cleaner, can\u0027t say if it\u0027s the better design or not.\n\nI think a struct is an improvement ofer a bunch of separate arguments.\n\n\u003e Was not aware of |processing_time_|, it should also be set in the VideoStreamDecoder (but that\u0027s for another CL).\n\nWhen you do that, you can delete the decode_time_ms from FrameInfo, right?\n \n\u003e I think at some point we have to decide if we want a VideoFrame (that represents just the decoded video frame, and timestamp I guess), or an RtcVideoFrame (that contains all kind of information relevant for an RTC system). Maybe the VideoFrameBuffer could already be considered to be the \"VideoFrame\" though...\n\nCurrent design has VideoFrameBuffer representing the pixels (in one of several possible ways), while VideoFrame carries the metadata + VideoFramebuffer reference. I think that\u0027s still a good design, even if VideoFrameBuffer has grown quite a bit larger than initially imagined. It would make some sense to share some meta data struct between classes representing raw frames and encoded frames, such a struct would then be a member of VideoFrame.",
      "parentUuid": "ea256229_e548c922",
      "range": {
        "startLine": 53,
        "startChar": 31,
        "endLine": 54,
        "endChar": 63
      },
      "revId": "26cb71794d1fe7b5f6aee60d2163ade1f70fa309",
      "serverId": "58829da1-049c-39fb-b951-ebdcd0984767",
      "unresolved": true
    },
    {
      "key": {
        "uuid": "9167f133_a25d9ba0",
        "filename": "api/video/video_stream_decoder.h",
        "patchSetId": 2
      },
      "lineNbr": 54,
      "author": {
        "id": 5527
      },
      "writtenOn": "2020-09-11T09:00:01Z",
      "side": 1,
      "message": "\u003e \u003e \u003e Is there any good reason to split meta data between VideoFrame and the new struct?\n\u003e \u003e \n\u003e \u003e The initial (current) design of OnDecodedFrame is just a mirroring of the DecodedImageCallback::Decoded callback, now that I added an additional member I though creating a FrameInfo struct was cleaner, can\u0027t say if it\u0027s the better design or not.\n\u003e \n\u003e I think a struct is an improvement ofer a bunch of separate arguments.\n\u003e \n\u003e \u003e Was not aware of |processing_time_|, it should also be set in the VideoStreamDecoder (but that\u0027s for another CL).\n\u003e \n\u003e When you do that, you can delete the decode_time_ms from FrameInfo, right?\n\nYes\n\n\u003e \u003e I think at some point we have to decide if we want a VideoFrame (that represents just the decoded video frame, and timestamp I guess), or an RtcVideoFrame (that contains all kind of information relevant for an RTC system). Maybe the VideoFrameBuffer could already be considered to be the \"VideoFrame\" though...\n\u003e \n\u003e Current design has VideoFrameBuffer representing the pixels (in one of several possible ways), while VideoFrame carries the metadata + VideoFramebuffer reference. I think that\u0027s still a good design, even if VideoFrameBuffer has grown quite a bit larger than initially imagined. It would make some sense to share some meta data struct between classes representing raw frames and encoded frames, such a struct would then be a member of VideoFrame.\n\nSGTM",
      "parentUuid": "bedce770_ffd3a324",
      "range": {
        "startLine": 53,
        "startChar": 31,
        "endLine": 54,
        "endChar": 63
      },
      "revId": "26cb71794d1fe7b5f6aee60d2163ade1f70fa309",
      "serverId": "58829da1-049c-39fb-b951-ebdcd0984767",
      "unresolved": true
    }
  ]
}