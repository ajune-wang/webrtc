{
  "comments": [
    {
      "unresolved": false,
      "key": {
        "uuid": "3c6ed48b_f6bba495",
        "filename": "/PATCHSET_LEVEL",
        "patchSetId": 15
      },
      "lineNbr": 0,
      "author": {
        "id": 5234
      },
      "writtenOn": "2022-02-01T13:37:07Z",
      "side": 1,
      "message": "Looks pretty good, a few questions.",
      "revId": "1223d96a01669c998badedb8db7318a1c4e76432",
      "serverId": "58829da1-049c-39fb-b951-ebdcd0984767"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "ee6eaeba_725610ef",
        "filename": "p2p/base/connection.cc",
        "patchSetId": 15
      },
      "lineNbr": 840,
      "author": {
        "id": 5234
      },
      "writtenOn": "2022-02-01T13:37:07Z",
      "side": 1,
      "message": "This moves SignalDestroyed so that it is called before, rather than after, this method returns. Intentional?",
      "range": {
        "startLine": 838,
        "startChar": 0,
        "endLine": 840,
        "endChar": 0
      },
      "revId": "1223d96a01669c998badedb8db7318a1c4e76432",
      "serverId": "58829da1-049c-39fb-b951-ebdcd0984767"
    },
    {
      "unresolved": false,
      "key": {
        "uuid": "db27fe85_a71f9775",
        "filename": "p2p/base/connection.cc",
        "patchSetId": 15
      },
      "lineNbr": 840,
      "author": {
        "id": 5508
      },
      "writtenOn": "2022-02-01T14:54:13Z",
      "side": 1,
      "message": "Yes, intentional. This was helpful in tracking down many places where  Connection objects were being destroyed via the Destroy() method along with deleting other objects. The problem was that the signal was not disconnected from the deleted subscribers. Subsequently there were pending uaf tasks in the thread\u0027s message queue. The tests passed because the pending tasks were leaked.\n\nAdded a comment.",
      "parentUuid": "ee6eaeba_725610ef",
      "range": {
        "startLine": 838,
        "startChar": 0,
        "endLine": 840,
        "endChar": 0
      },
      "revId": "1223d96a01669c998badedb8db7318a1c4e76432",
      "serverId": "58829da1-049c-39fb-b951-ebdcd0984767"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "bc420b62_1c195839",
        "filename": "p2p/base/connection.cc",
        "patchSetId": 15
      },
      "lineNbr": 840,
      "author": {
        "id": 5053
      },
      "writtenOn": "2022-02-25T02:24:21Z",
      "side": 1,
      "message": "I don\u0027t quite understand; other objects hooked up to this signal should also live on the network thread, and their destructors (called on the network thread) will disconnect the signal before the task executes. Do you have an example?\n\nI wonder if calling SignalDestroyed without unwinding the stack first is causing problems? Could be something like:\n\n1. Port::DestroyAllConnections calls Destroy on all its connections_ (without making a temporary copy; previously it didn\u0027t have to)\n2. P2PTransportChannel::OnConnectionDestroyed calls UpdateState, which ends up destroying another connection due to a timeout or whatever other criteria\n3. Port::OnConnectionDestroyed removes this second connection from connections_, modifying the array while we\u0027re iterating it\n\nNot sure if this could explain the stack traces we\u0027re seeing though, as I\u0027d expect things to blow up in DestroyAllConnections and not the posted Destroy task",
      "parentUuid": "db27fe85_a71f9775",
      "range": {
        "startLine": 838,
        "startChar": 0,
        "endLine": 840,
        "endChar": 0
      },
      "revId": "1223d96a01669c998badedb8db7318a1c4e76432",
      "serverId": "58829da1-049c-39fb-b951-ebdcd0984767"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "cf77042f_f4eda9a9",
        "filename": "p2p/base/connection.cc",
        "patchSetId": 15
      },
      "lineNbr": 840,
      "author": {
        "id": 5508
      },
      "writtenOn": "2022-02-25T11:30:55Z",
      "side": 1,
      "message": "The sigslot has raw pointers to objects that do (or rather, did) not disconnect prior to deletion. What was happening was that the deferred deletion of Connection could happen after those objects were deleted. Tests that would trigger those problems.\n\nBtw, looks like the bots are pointing out a few examples of leaks and uafs to us as part of the revert:\nhttps://chromium-swarm.appspot.com/task?id\u003d594792bd36c35510 and here\nhttps://chromium-swarm.appspot.com/task?id\u003d594952d36b6a7810\n\nWrt `previously it didn\u0027t have to` -\nActually it does and did [1]. Making temporary copies is not something that was introduced by these changes.\n\nBut secondly, I think the core issue more an artifact of the design and basically a built-in problem that we have.\n\nThe \"Destroy() + async deletion\" is a workaround to avoid a crash in those places where there\u0027s a re-entrant dependency from the class that triggers the deletion and is also subscribed to a callback related to that deletion that in turn modifies the list being iterated over.\n\nInstead of avoiding the callback (require disconnect first), the deletion is deferred to happen later. The side effect of that though is that the time and order of destruction is no longer deterministic. As the stack unwinds it\u0027s hard to know where there might be raw pointers in use for the object that has been scheduled to be deleted as well as what objects may have been deleted at that time that the object then refers to because we\u0027re not strict about disconnecting from sigslots.\n\n\n[1]: https://source.chromium.org/chromium/chromium/src/+/main:third_party/webrtc/p2p/base/port.cc;l\u003d191?q\u003dPort\u0026ss\u003dchromium",
      "parentUuid": "bc420b62_1c195839",
      "range": {
        "startLine": 838,
        "startChar": 0,
        "endLine": 840,
        "endChar": 0
      },
      "revId": "1223d96a01669c998badedb8db7318a1c4e76432",
      "serverId": "58829da1-049c-39fb-b951-ebdcd0984767"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "b370e45e_4dfcd51b",
        "filename": "p2p/base/connection.cc",
        "patchSetId": 15
      },
      "lineNbr": 840,
      "author": {
        "id": 5053
      },
      "writtenOn": "2022-02-25T20:52:40Z",
      "side": 1,
      "message": "\u003e The sigslot has raw pointers to objects that do (or rather, did) not disconnect prior to deletion. \n\nsigslot::~has_slots() calls disconnect_all(), so how is that happening?\n\n\u003e Actually it does [need to make a copy of the connection list] and did [1].\n\nNot in Port::DestroyAllConnections(). I don\u0027t know why making a copy would have been necessary, since Destroy previously didn\u0027t do anything but post a task. Maybe it previously called SignalDestroyed synchronously, further back in the code history.\n\n\u003e Instead of avoiding the callback (require disconnect first), the deletion is deferred to happen later. \n\nIn most places I do see disconnect being called first, but you can have object A delete a Connection which is observed by the object B, causing it to delete another Connection which is observed by object A, as in my example above.",
      "parentUuid": "cf77042f_f4eda9a9",
      "range": {
        "startLine": 838,
        "startChar": 0,
        "endLine": 840,
        "endChar": 0
      },
      "revId": "1223d96a01669c998badedb8db7318a1c4e76432",
      "serverId": "58829da1-049c-39fb-b951-ebdcd0984767"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "6bdbcdd5_1980fcd0",
        "filename": "p2p/base/connection.cc",
        "patchSetId": 15
      },
      "lineNbr": 844,
      "author": {
        "id": 5234
      },
      "writtenOn": "2022-02-01T13:37:07Z",
      "side": 1,
      "message": "Prefer absl::WrapUnique.\n\nAlso, reason for destroying the object as its own task (post to the same thread) is unclear. Can it be explained in a comment?",
      "range": {
        "startLine": 844,
        "startChar": 33,
        "endLine": 844,
        "endChar": 48
      },
      "revId": "1223d96a01669c998badedb8db7318a1c4e76432",
      "serverId": "58829da1-049c-39fb-b951-ebdcd0984767"
    },
    {
      "unresolved": false,
      "key": {
        "uuid": "9f54e61e_8c101ade",
        "filename": "p2p/base/connection.cc",
        "patchSetId": 15
      },
      "lineNbr": 844,
      "author": {
        "id": 5508
      },
      "writtenOn": "2022-02-01T14:54:13Z",
      "side": 1,
      "message": "Done.\n\nPosting to the same thread, preserves the previous behavior.\n\nFrom gleaning at the code I think it\u0027s to guard against callers up stack that still hold a pointer to a Connection object, still refer to its state after the call to Destroy() and the stack needs to be be unwound. However, there are quite a few raw pointers flying around in these classes and for example a mismatch of lifetimes between the Connection and Port classes. Some of the code seems to have grown \u0027organically\u0027 with band-aid fixes for what could be said is a design problem. That could be the reason for why Destroy() is done this way. Another example where I saw something similar is in TCPConnection::CreateOutgoingTcpSocket() when FailAndPrune() needs to be called.\n\nBtw another thing that\u0027s different here is that if PostTask() fails, then the task will be deleted. That\u0027s why I move the ownership into the capture section rather than delete the object within the body of the function. This guarantees that the object is always deleted, but in the case of PostTask failure, it means that the object will be deleted from within Destroy().",
      "parentUuid": "6bdbcdd5_1980fcd0",
      "range": {
        "startLine": 844,
        "startChar": 33,
        "endLine": 844,
        "endChar": 48
      },
      "revId": "1223d96a01669c998badedb8db7318a1c4e76432",
      "serverId": "58829da1-049c-39fb-b951-ebdcd0984767"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "e47f163d_3d89c9ec",
        "filename": "p2p/base/tcp_port.cc",
        "patchSetId": 15
      },
      "lineNbr": 372,
      "author": {
        "id": 5234
      },
      "writtenOn": "2022-02-01T13:37:07Z",
      "side": 1,
      "message": "Are there ordering subtleties that make it necessary to use SetNotAlive explicitly, rather than using ScopedTaskSafety? If so, worthy of a comment.",
      "range": {
        "startLine": 371,
        "startChar": 0,
        "endLine": 372,
        "endChar": 33
      },
      "revId": "1223d96a01669c998badedb8db7318a1c4e76432",
      "serverId": "58829da1-049c-39fb-b951-ebdcd0984767"
    },
    {
      "unresolved": false,
      "key": {
        "uuid": "baabbe06_40a37a1c",
        "filename": "p2p/base/tcp_port.cc",
        "patchSetId": 15
      },
      "lineNbr": 372,
      "author": {
        "id": 5508
      },
      "writtenOn": "2022-02-01T14:54:13Z",
      "side": 1,
      "message": "Nope, switching to ScopedTaskSafety.",
      "parentUuid": "e47f163d_3d89c9ec",
      "range": {
        "startLine": 371,
        "startChar": 0,
        "endLine": 372,
        "endChar": 33
      },
      "revId": "1223d96a01669c998badedb8db7318a1c4e76432",
      "serverId": "58829da1-049c-39fb-b951-ebdcd0984767"
    }
  ]
}