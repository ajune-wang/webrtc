{
  "comments": [
    {
      "unresolved": true,
      "key": {
        "uuid": "bac680e1_1ac65afa",
        "filename": "api/video/video_frame.h",
        "patchSetId": 3
      },
      "lineNbr": 197,
      "author": {
        "id": 5234
      },
      "writtenOn": "2020-10-23T13:13:11Z",
      "side": 1,
      "message": "It seems a bit strange to me to have a unit of frames here, since the playout delay extension signals time in ms.\n\nIt would seem more natural with a max_render_delay_ms, or maybe even better with a timestamp with latest render time. Would be good to know how it interacts with the other frame timestamps, timestamp_us() and render_time_ms() below, I\u0027m not really familiar with how they are used on the receive side.\n\nMore abstractly, timestamps make sense as frame metadata, but a configured maximum delay isn\u0027t quite a per-frame property, is it?",
      "range": {
        "startLine": 189,
        "startChar": 0,
        "endLine": 197,
        "endChar": 0
      },
      "revId": "fa0b877ad5098eee73767e01c92b4b984a926101",
      "serverId": "58829da1-049c-39fb-b951-ebdcd0984767"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "fb380a07_ddce56d3",
        "filename": "api/video/video_frame.h",
        "patchSetId": 3
      },
      "lineNbr": 197,
      "author": {
        "id": 7641
      },
      "writtenOn": "2020-10-26T09:45:14Z",
      "side": 1,
      "message": "What we\u0027re trying to achieve is to postpone the decision of dropping a frame or not to as late as possible. We\u0027ve found that a pragmatic way of making this decision possible in the compositor is to provide the information included in |max_composition_delay_in_frames|. The renderer will take different decisions depending on the total queue size in relation to |max_composition_delay_in_frames|.\n\nI\u0027ll investigate what the consequences would be of refactoring to a |max_render_delay_ms|, for now I would like to keep counting number of frames to enable wider experimentation with this strategy which has shown positive results in local experiments.\n\nI agree that it\u0027s not a per-frame property in a conventional way. However, it\u0027s a per-frame property in the sense that it provides information about how relevant this frame is in a low-latency context. If there are several frames in the decode queue, we would set |max_composition_delay_in_frames| to a lower number and indicate to the compositor that this frame might be dropped because there are several newer frames coming soon.",
      "parentUuid": "bac680e1_1ac65afa",
      "range": {
        "startLine": 189,
        "startChar": 0,
        "endLine": 197,
        "endChar": 0
      },
      "revId": "fa0b877ad5098eee73767e01c92b4b984a926101",
      "serverId": "58829da1-049c-39fb-b951-ebdcd0984767"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "8f1bf6b7_df4ca5f6",
        "filename": "api/video/video_frame.h",
        "patchSetId": 3
      },
      "lineNbr": 197,
      "author": {
        "id": 5234
      },
      "writtenOn": "2020-10-26T12:12:13Z",
      "side": 1,
      "message": "\u003e What we\u0027re trying to achieve is to postpone the decision of dropping a frame or not to as late as possible.\n\nI\u0027m a bit puzzled why there\u0027s any need to buffer frames both before and after decoder, but I guess one reason is that the pre-decode buffer can\u0027t drop any frames (except in special cases like next frame being a key frame).\n\n\u003e I\u0027ll investigate what the consequences would be of refactoring to a |max_render_delay_ms|, for now I would like to keep counting number of frames to enable wider experimentation with this strategy which has shown positive results in local experiments.\n\nThe reason I asked is that (1) ms is a better defined unit, and (2) it would be nice if the relation to render_time_ms was clear (I don\u0027t know if and how the latter is used).\n\n\u003e I agree that it\u0027s not a per-frame property in a conventional way. However, it\u0027s a per-frame property in the sense that it provides information about how relevant this frame is in a low-latency context. If there are several frames in the decode queue, we would set |max_composition_delay_in_frames| to a lower number and indicate to the compositor that this frame might be dropped because there are several newer frames coming soon.\n\nTo postpone decision making, maybe it would be even better to attach the number of decodable frames in the decode buffer? \n\nAnother question: Is there any logic in elsewhere in webrtc to discard frames after decoding? I take it frame dropping with max_delay \u003d 0 happens somewhere in webrtc?",
      "parentUuid": "fb380a07_ddce56d3",
      "range": {
        "startLine": 189,
        "startChar": 0,
        "endLine": 197,
        "endChar": 0
      },
      "revId": "fa0b877ad5098eee73767e01c92b4b984a926101",
      "serverId": "58829da1-049c-39fb-b951-ebdcd0984767"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "ade659b4_5a61b246",
        "filename": "api/video/video_frame.h",
        "patchSetId": 3
      },
      "lineNbr": 197,
      "author": {
        "id": 7641
      },
      "writtenOn": "2020-10-26T12:58:31Z",
      "side": 1,
      "message": "\u003e \u003e What we\u0027re trying to achieve is to postpone the decision of dropping a frame or not to as late as possible.\n\u003e \n\u003e I\u0027m a bit puzzled why there\u0027s any need to buffer frames both before and after decoder, but I guess one reason is that the pre-decode buffer can\u0027t drop any frames (except in special cases like next frame being a key frame).\n\nDue to network jitter it may happen that we get several decodable frames at once. The decode times also varies which is why there will be frames in the pre decode buffer. The reason why there\u0027s a need to buffer frames post-decode is because WebRTC is not synchronized with the rendering. What happens currently with min/max playout delay\u003d\u003d0 is that two or more frames may be submitted during the same rendering interval resulting in that two of the frames are not rendered.\n\n\n\u003e \n\u003e \u003e I\u0027ll investigate what the consequences would be of refactoring to a |max_render_delay_ms|, for now I would like to keep counting number of frames to enable wider experimentation with this strategy which has shown positive results in local experiments.\n\u003e \n\u003e The reason I asked is that (1) ms is a better defined unit, and (2) it would be nice if the relation to render_time_ms was clear (I don\u0027t know if and how the latter is used).\n\nThe current behavior for min/max playout delay\u003d\u003d0 is to not set the render time at all.\n\n\u003e \n\u003e \u003e I agree that it\u0027s not a per-frame property in a conventional way. However, it\u0027s a per-frame property in the sense that it provides information about how relevant this frame is in a low-latency context. If there are several frames in the decode queue, we would set |max_composition_delay_in_frames| to a lower number and indicate to the compositor that this frame might be dropped because there are several newer frames coming soon.\n\u003e \n\u003e To postpone decision making, maybe it would be even better to attach the number of decodable frames in the decode buffer?\n\nYes, that\u0027s also an option but it would require a hard decision on the threshold to use before dropping frames. If we find a good configuration that always \"work\" that\u0027s worth considering. \n\n\u003e \n\u003e Another question: Is there any logic in elsewhere in webrtc to discard frames after decoding? I take it frame dropping with max_delay \u003d 0 happens somewhere in webrtc?\n\nIf I recall correctly the only place where we drop frames in WebRTC post decode is in generic_decoder if we cannot find the corresponding metadata to add back to the decoded video frame. Otherwise all decoded frames should be submitted for rendering. There\u0027s an implicit dropping of frames for max playout delay \u003d 0 as described above.",
      "parentUuid": "8f1bf6b7_df4ca5f6",
      "range": {
        "startLine": 189,
        "startChar": 0,
        "endLine": 197,
        "endChar": 0
      },
      "revId": "fa0b877ad5098eee73767e01c92b4b984a926101",
      "serverId": "58829da1-049c-39fb-b951-ebdcd0984767"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "742effc0_e479df97",
        "filename": "api/video/video_frame.h",
        "patchSetId": 3
      },
      "lineNbr": 197,
      "author": {
        "id": 5234
      },
      "writtenOn": "2020-10-26T13:14:48Z",
      "side": 1,
      "message": "\u003e \u003e To postpone decision making, maybe it would be even better to attach the number of decodable frames in the decode buffer?\n\u003e \n\u003e Yes, that\u0027s also an option but it would require a hard decision on the threshold to use before dropping frames. If we find a good configuration that always \"work\" that\u0027s worth considering. \n\nTo me it seems like the logic will be divided into two places: Webrtc, translating size of pre-decode buffer to max_composition_delay_in_frames, and chrome rendering that uses this value together with it\u0027s size of the post-decode buffering and some threshold values to control frame drop logic.\n\nWouldn\u0027t it be easier to tune and experiment with all the logic in one place?\n\n\u003e There\u0027s an implicit dropping of frames for max playout delay \u003d 0 as described above.\n\nI\u0027m afraid I don\u0027t get the details here. In this case, are all frames still passed on to the application, but the application drops them? Or are they discarded somewhere in webrtc?",
      "parentUuid": "ade659b4_5a61b246",
      "range": {
        "startLine": 189,
        "startChar": 0,
        "endLine": 197,
        "endChar": 0
      },
      "revId": "fa0b877ad5098eee73767e01c92b4b984a926101",
      "serverId": "58829da1-049c-39fb-b951-ebdcd0984767"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "14fdbfc4_c0accb3b",
        "filename": "api/video/video_frame.h",
        "patchSetId": 3
      },
      "lineNbr": 197,
      "author": {
        "id": 7641
      },
      "writtenOn": "2020-10-26T13:52:04Z",
      "side": 1,
      "message": "\u003e \u003e \u003e To postpone decision making, maybe it would be even better to attach the number of decodable frames in the decode buffer?\n\u003e \u003e \n\u003e \u003e Yes, that\u0027s also an option but it would require a hard decision on the threshold to use before dropping frames. If we find a good configuration that always \"work\" that\u0027s worth considering. \n\u003e \n\u003e To me it seems like the logic will be divided into two places: Webrtc, translating size of pre-decode buffer to max_composition_delay_in_frames, and chrome rendering that uses this value together with it\u0027s size of the post-decode buffering and some threshold values to control frame drop logic.\n\u003e \n\u003e Wouldn\u0027t it be easier to tune and experiment with all the logic in one place?\n\nI expect that most of the experimentation will be by testing different playout delays and perhaps adjusting the renderer algorithm in Chrome.\n\nAn alternative would be to add 2 fields to VideoFrame: |max_playout_delay| and |number_of_frames_in_predecode_buffer|. I open for this as well, but was thinking that |max_composition_delay| fits better into VideoFrame than |number_of_frames_in_predecode_buffer|.\nWDYT?\n \n\u003e \u003e There\u0027s an implicit dropping of frames for max playout delay \u003d 0 as described above.\n\u003e \n\u003e I\u0027m afraid I don\u0027t get the details here. In this case, are all frames still passed on to the application, but the application drops them? Or are they discarded somewhere in webrtc?\n\nThe frames are dropped by the application. At the moment, frames are dropped randomly based on when they are submitted to the compositor in relation to the rendering intervals which are unknown to WebRTC. With this change, the idea is to be able to control when the frames are dropped.",
      "parentUuid": "742effc0_e479df97",
      "range": {
        "startLine": 189,
        "startChar": 0,
        "endLine": 197,
        "endChar": 0
      },
      "revId": "fa0b877ad5098eee73767e01c92b4b984a926101",
      "serverId": "58829da1-049c-39fb-b951-ebdcd0984767"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "d05a02e7_c4d0e94c",
        "filename": "api/video/video_frame.h",
        "patchSetId": 3
      },
      "lineNbr": 197,
      "author": {
        "id": 5234
      },
      "writtenOn": "2020-10-26T14:23:06Z",
      "side": 1,
      "message": "\u003e An alternative would be to add 2 fields to VideoFrame: |max_playout_delay| and |number_of_frames_in_predecode_buffer|. I open for this as well, but was thinking that |max_composition_delay| fits better into VideoFrame than |number_of_frames_in_predecode_buffer|.\n\u003e WDYT?\n\nI guess |number_of_frames_in_predecode_buffer| is good enough to get started with experiments.\n\nFor alternatives, it would make some sense to me to provide |max_playout_delay| to the application via some other path, populate render_time_ms / timestamp_us with something that\u0027s useful for render scheduling, and add a flag to VideoFrame to say that the decode buffer is empty, or in other words, that at the moment, no later decodable frame has been received. Which means that the frame is a poor candidate for the frame dropping logic. Which all sounds like some non-obvious design work.\n\n\u003e The frames are dropped by the application. At the moment, frames are dropped randomly based on when they are submitted to the compositor in relation to the rendering intervals which are unknown to WebRTC.\n\nOk, I have to guess a little. So assume the application uses 33 ms render interval (30 fps), then at time t \u003d 33*n ms, it renders the most recently received frame from webrtc (which might be the same as the previous one, if no new one has been seen).\n\nI can understand that gives a crappy result in case frames are arriving at 30 fps on average, but with some inevitable jitter. A buffer of just one or two frames before the renderer could help a lot.",
      "parentUuid": "14fdbfc4_c0accb3b",
      "range": {
        "startLine": 189,
        "startChar": 0,
        "endLine": 197,
        "endChar": 0
      },
      "revId": "fa0b877ad5098eee73767e01c92b4b984a926101",
      "serverId": "58829da1-049c-39fb-b951-ebdcd0984767"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "75b59c71_693ae509",
        "filename": "modules/video_coding/generic_decoder.h",
        "patchSetId": 3
      },
      "lineNbr": 88,
      "author": {
        "id": 5234
      },
      "writtenOn": "2020-10-23T13:13:11Z",
      "side": 1,
      "message": "nit: Put the _ last on new member variables.",
      "range": {
        "startLine": 80,
        "startChar": 0,
        "endLine": 88,
        "endChar": 75
      },
      "revId": "fa0b877ad5098eee73767e01c92b4b984a926101",
      "serverId": "58829da1-049c-39fb-b951-ebdcd0984767"
    }
  ]
}