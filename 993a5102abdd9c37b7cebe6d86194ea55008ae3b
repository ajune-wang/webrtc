{
  "comments": [
    {
      "key": {
        "uuid": "0efe388f_50f777cc",
        "filename": "/COMMIT_MSG",
        "patchSetId": 9
      },
      "lineNbr": 12,
      "author": {
        "id": 5053
      },
      "writtenOn": "2018-06-18T21:02:32Z",
      "side": 1,
      "message": "Should update this message before landing.",
      "revId": "993a5102abdd9c37b7cebe6d86194ea55008ae3b",
      "serverId": "58829da1-049c-39fb-b951-ebdcd0984767",
      "unresolved": true
    },
    {
      "key": {
        "uuid": "40a7e78b_021d1762",
        "filename": "/COMMIT_MSG",
        "patchSetId": 9
      },
      "lineNbr": 12,
      "author": {
        "id": 5800
      },
      "writtenOn": "2018-06-18T22:15:47Z",
      "side": 1,
      "message": "Done",
      "parentUuid": "0efe388f_50f777cc",
      "revId": "993a5102abdd9c37b7cebe6d86194ea55008ae3b",
      "serverId": "58829da1-049c-39fb-b951-ebdcd0984767",
      "unresolved": false
    },
    {
      "key": {
        "uuid": "f4b2c0d2_6b656cbd",
        "filename": "pc/peerconnection_rampup_tests.cc",
        "patchSetId": 9
      },
      "lineNbr": 42,
      "author": {
        "id": 5053
      },
      "writtenOn": "2018-06-18T21:02:32Z",
      "side": 1,
      "message": "I don\u0027t really understand this comment; where does 1.7 come from? And if the max is 1.7Mbps why does it limit throughput to 1Mbps and not 1.7?",
      "revId": "993a5102abdd9c37b7cebe6d86194ea55008ae3b",
      "serverId": "58829da1-049c-39fb-b951-ebdcd0984767",
      "unresolved": true
    },
    {
      "key": {
        "uuid": "4b9b37db_8306713c",
        "filename": "pc/peerconnection_rampup_tests.cc",
        "patchSetId": 9
      },
      "lineNbr": 42,
      "author": {
        "id": 5800
      },
      "writtenOn": "2018-06-18T22:15:47Z",
      "side": 1,
      "message": "The max bitrate comes from the configured max here:\nhttps://cs.chromium.org/chromium/src/third_party/webrtc/media/engine/webrtcvideoengine.cc?l\u003d328\n\nIt\u0027s not a \"hard\" limit at 1Mbps, but the encoder\u0027s throughput never goes above this when testing with an unlimited virtual network. I\u0027m assuming this is due to some shortcuts it takes with encoding the SquareGenerator video source. The reason I chose 4/3 of this max throughput was based off of the rampup_tests.cc:\nhttps://cs.chromium.org/chromium/src/third_party/webrtc/call/rampup_tests.cc?l\u003d406\n\nI updated the comment. Let me know if it looks good to you.",
      "parentUuid": "f4b2c0d2_6b656cbd",
      "revId": "993a5102abdd9c37b7cebe6d86194ea55008ae3b",
      "serverId": "58829da1-049c-39fb-b951-ebdcd0984767",
      "unresolved": true
    },
    {
      "key": {
        "uuid": "84d497dc_3064ea68",
        "filename": "pc/peerconnection_rampup_tests.cc",
        "patchSetId": 9
      },
      "lineNbr": 42,
      "author": {
        "id": 5053
      },
      "writtenOn": "2018-06-19T18:56:45Z",
      "side": 1,
      "message": "I don\u0027t see how the \"4/3\" is applicable here; rampup_tests works by waiting until the BWE ramps up to 3/4 of the network\u0027s capacity, while this test (at least now) doesn\u0027t even have a specific target value it\u0027s waiting for.\n\nIf the encoder only produces a max of ~1Mbps, then we should set the network capacity to something *less* than that (or make the generated video more complex, increasing num_squares or resolution), so we don\u0027t end up \"application limited\". We want to be testing bandwidth estimation, not encoding; we wouldn\u0027t want an improvement in the efficiency of the encoder to show up as a regression in this test.",
      "parentUuid": "4b9b37db_8306713c",
      "revId": "993a5102abdd9c37b7cebe6d86194ea55008ae3b",
      "serverId": "58829da1-049c-39fb-b951-ebdcd0984767",
      "unresolved": true
    },
    {
      "key": {
        "uuid": "2b937021_e866657e",
        "filename": "pc/peerconnection_rampup_tests.cc",
        "patchSetId": 9
      },
      "lineNbr": 42,
      "author": {
        "id": 5800
      },
      "writtenOn": "2018-06-19T22:52:07Z",
      "side": 1,
      "message": "This value did push the network\u0027s capacity, but you make a good point that we don\u0027t want encoder efficiency improvements to cause alerts. How about half of the max throughput of the encoder (500 Kbps)?  \n\nAs a side note I played around with the network bandwidth values and I found some interesting results. It seems that when the network bandwidth limits the throughput of the encoder, then the bwe \u0026 the encoder throughput actually drop a significant amount. Not sure what the root cause would be, perhaps built up queues? It happens over UDP as well. For example I get the following two results:\n* network bandwidth \u003d 1.5 Mbps\n  BWE \u003d 1426066\n  encoder throughput \u003d 1036616\n* network bandwidth \u003d 1 Mbps\n  BWE \u003d 543417\n  encoder throughput \u003d 553288\n* network bandwidth \u003d 500 Kbps\n  BWE \u003d 276061\n  encoder throughput \u003d 282568\n\nIn the above tests, I would expect the bwe \u0026 throughput to be closer to the actual network bandwidth limit (same with 500 Kbps).\n\nAnyways, I updated the limit to 500 kbps. Let me know what you think.",
      "parentUuid": "84d497dc_3064ea68",
      "revId": "993a5102abdd9c37b7cebe6d86194ea55008ae3b",
      "serverId": "58829da1-049c-39fb-b951-ebdcd0984767",
      "unresolved": true
    },
    {
      "key": {
        "uuid": "861ed147_e9ffd719",
        "filename": "pc/peerconnection_rampup_tests.cc",
        "patchSetId": 9
      },
      "lineNbr": 42,
      "author": {
        "id": 5053
      },
      "writtenOn": "2018-06-19T23:50:49Z",
      "side": 1,
      "message": "500kbps may be on the low side, since we also want a decent margin between \"BWE not working at all\" (starts at 300kbps, right?) and \"working as expected\".\n\nAs for why you\u0027re seeing such a significant drop, I\u0027m guessing it\u0027s either due to the poor simulation or the BWE\u0027s sensitivity to building up queues. Or you may just be catching it at the bottom end of the sawtooth pattern? I don\u0027t really know without investigating.",
      "parentUuid": "2b937021_e866657e",
      "revId": "993a5102abdd9c37b7cebe6d86194ea55008ae3b",
      "serverId": "58829da1-049c-39fb-b951-ebdcd0984767",
      "unresolved": true
    },
    {
      "key": {
        "uuid": "c707b7f9_96d393c7",
        "filename": "pc/peerconnection_rampup_tests.cc",
        "patchSetId": 9
      },
      "lineNbr": 42,
      "author": {
        "id": 5800
      },
      "writtenOn": "2018-06-20T21:38:06Z",
      "side": 1,
      "message": "As discussed offline, I tested the bwe failure case by undoing a fix for a tcp related regression. The failing case\u0027s estimate is 10 kbps, so 500 kbps should work fine. Although there\u0027s no harm in ramping up higher, and it is probably preferred for catching regressions. I updated the default generated number of squares to be higher and this allows the encoder to get to its max bitrate, and changed the network bandwidth to 1 Mbps. \n\nI investigated the drop a little bit as well. I measured the total throughput by pulling the bytes_sent stat from the ICE candidate pair, and found that it reaches much closer to the total bandwidth (for example ~940 kbps when video is getting ~760 kbps). This makes me believe that a good portion of the difference is due to different overheads, and the rest is due to congestion control being sensitive to overuse.",
      "parentUuid": "861ed147_e9ffd719",
      "revId": "993a5102abdd9c37b7cebe6d86194ea55008ae3b",
      "serverId": "58829da1-049c-39fb-b951-ebdcd0984767",
      "unresolved": false
    }
  ]
}