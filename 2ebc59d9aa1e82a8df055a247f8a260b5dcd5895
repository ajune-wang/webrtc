{
  "comments": [
    {
      "unresolved": false,
      "key": {
        "uuid": "b5a3b71c_522f7b5f",
        "filename": "/PATCHSET_LEVEL",
        "patchSetId": 7
      },
      "lineNbr": 0,
      "author": {
        "id": 5142
      },
      "writtenOn": "2021-02-17T12:48:07Z",
      "side": 1,
      "message": "Ilya can you take a look? I should add a unit test but I have a question about update rect and I want to get an OK that this is the right approach.",
      "revId": "2ebc59d9aa1e82a8df055a247f8a260b5dcd5895",
      "serverId": "58829da1-049c-39fb-b951-ebdcd0984767"
    },
    {
      "unresolved": false,
      "key": {
        "uuid": "85001970_4ca1232f",
        "filename": "/PATCHSET_LEVEL",
        "patchSetId": 7
      },
      "lineNbr": 0,
      "author": {
        "id": 5117
      },
      "writtenOn": "2021-02-17T13:45:00Z",
      "side": 1,
      "message": "I just realized that this approach might be infeasible.\nThe feedback is delayed. So consider this situation: Encoder is configured with ScaleDownBy factor of 2. No adaptation, capture is 720p. So your idea is to capture in 360p and pass it to webrtc.\n\nBut what happens if the encoder is suddenly reconfigured to have a ScaleDownBy factor of 1?\nWebrtc would want full size image, but it would take a couple of frames before the capturer gets the feedback and starts sending full size images.\n\nWhat to do meanwhile? It\u0027s a completely new state: encoder is encoding 360p, but it wants 720p.\nHow to calculate that?",
      "revId": "2ebc59d9aa1e82a8df055a247f8a260b5dcd5895",
      "serverId": "58829da1-049c-39fb-b951-ebdcd0984767"
    },
    {
      "unresolved": false,
      "key": {
        "uuid": "242ce575_65d518c5",
        "filename": "/PATCHSET_LEVEL",
        "patchSetId": 7
      },
      "lineNbr": 0,
      "author": {
        "id": 5117
      },
      "writtenOn": "2021-02-17T13:46:49Z",
      "side": 1,
      "message": "Well, potentially dropping frames until the full resolution comes through is a possible solution.",
      "revId": "2ebc59d9aa1e82a8df055a247f8a260b5dcd5895",
      "serverId": "58829da1-049c-39fb-b951-ebdcd0984767"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "362be8e9_04dffad5",
        "filename": "/PATCHSET_LEVEL",
        "patchSetId": 7
      },
      "lineNbr": 0,
      "author": {
        "id": 5142
      },
      "writtenOn": "2021-02-17T14:20:36Z",
      "side": 1,
      "message": "In the case of 720p capture, 480p adaptation and 360p resolution what I want to avoid is having to produce that 480p frame.\n\nYou are right, if scaleResolutionDownBy is modified and we only pass in 360p then we don\u0027t know what to do for the 480p frame.\n\nI have a proposed solution that is \"for free\". We can always pass in the 720p video frame. In that case we would have 720p + 360p and if it turns out that suddenly we want 480p we can downscale 720p to 480p inside VideoStreamEncoder. This means that:\n1. In the normal case, we get rid of the 480p unnecessary scale.\n2. In the worst-case edge-case, we do 720p -\u003e 480p downscale. This is what Chromium already does today, so the only difference is that this would be part of the already-existing VSE downscale step.",
      "parentUuid": "85001970_4ca1232f",
      "revId": "2ebc59d9aa1e82a8df055a247f8a260b5dcd5895",
      "serverId": "58829da1-049c-39fb-b951-ebdcd0984767"
    },
    {
      "unresolved": false,
      "key": {
        "uuid": "efdb3e39_b2b9e321",
        "filename": "/PATCHSET_LEVEL",
        "patchSetId": 7
      },
      "lineNbr": 0,
      "author": {
        "id": 5142
      },
      "writtenOn": "2021-02-17T14:20:36Z",
      "side": 1,
      "message": "I will get back to you when I have updated the CL so that we can guarantee to always have a frame that is at least as big as the adapted video size. Then we can handle the edge case with minimal number of downscales and not having to drop frames even in the worst case.",
      "revId": "2ebc59d9aa1e82a8df055a247f8a260b5dcd5895",
      "serverId": "58829da1-049c-39fb-b951-ebdcd0984767"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "120d72ba_8a55c582",
        "filename": "/PATCHSET_LEVEL",
        "patchSetId": 7
      },
      "lineNbr": 0,
      "author": {
        "id": 5117
      },
      "writtenOn": "2021-02-17T14:36:27Z",
      "side": 1,
      "message": "In that case, I propose to not change anything in webrtc. At least in the interface.\n\nWebRtcVideoFrameAdapter should contain the full size image and downscaled copies. When they should be accessed via CropAndScaleBy overriden VideoFrameBuffer method: The method should return a copy with soft-applied scaling. When ToI420() or GetMemoryMappedFrame() is called, the cache of prescaled images is checked if it already has the correct size.\nThat way if only scaleDownBy\u003d2 image is encoded, only that will be requested and no actual 480p scaling would be done.\n\n\nTo make it work you need to change VideoStreamEncoder to not call GetMemoryMappedFrame() and do these calls in SW encoders themselves.\n\nYou also need to override CropAndScaleBy in WebRtcVideoFrameAdapter.",
      "parentUuid": "362be8e9_04dffad5",
      "revId": "2ebc59d9aa1e82a8df055a247f8a260b5dcd5895",
      "serverId": "58829da1-049c-39fb-b951-ebdcd0984767"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "2208f78e_6d5c40da",
        "filename": "/PATCHSET_LEVEL",
        "patchSetId": 7
      },
      "lineNbr": 0,
      "author": {
        "id": 5142
      },
      "writtenOn": "2021-02-17T15:11:04Z",
      "side": 1,
      "message": "OK this idea is growing on me after my initial pushback.\n\nSo in this case, would we have a VideoFrame that advertises itself as height()\u003d\u003d480p but internally the only buffers that have been created are 720p and 360p until encoding happens and the final resolution is decided?",
      "parentUuid": "120d72ba_8a55c582",
      "revId": "2ebc59d9aa1e82a8df055a247f8a260b5dcd5895",
      "serverId": "58829da1-049c-39fb-b951-ebdcd0984767"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "74ce1258_6148ca6a",
        "filename": "api/video/video_sink_interface.h",
        "patchSetId": 7
      },
      "lineNbr": 49,
      "author": {
        "id": 5117
      },
      "writtenOn": "2021-02-17T13:45:00Z",
      "side": 1,
      "message": "I thought the pre-scaled images would be passed via RtcVideoFrameAdapter, where scaling operation would be no-op. That way, webrtc shouldn\u0027t know about chrome-specific mechanism.\nI believe abstracting all the implementation details about pre-scaled frames in chrome land would be better.\n\nPassing vector of frames everywhere in webrtc doesn\u0027t seem to be such a good idea. Also, passing a vector of pointers is dangerous, and it introduce UaF (see comments in other files).\n\nInstead, maybe we could have an additional vector of VideoFrameBuffers inside?",
      "range": {
        "startLine": 49,
        "startChar": 24,
        "endLine": 49,
        "endChar": 69
      },
      "revId": "2ebc59d9aa1e82a8df055a247f8a260b5dcd5895",
      "serverId": "58829da1-049c-39fb-b951-ebdcd0984767"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "adbf4e2c_33c9b009",
        "filename": "api/video/video_sink_interface.h",
        "patchSetId": 7
      },
      "lineNbr": 49,
      "author": {
        "id": 5142
      },
      "writtenOn": "2021-02-17T14:20:36Z",
      "side": 1,
      "message": "I don\u0027t consider the fact that there exists multiple versions of the frame an \"implementation detail\". WebRTC asks for multiple frames because it wants to encode multiple frames and so it gets multiple frames. It\u0027s pretty straight-forward.\n\nConsider simulcast, we want to encode frame A, B and C. And we have frame A, B and C available in Chromium as a set of media::VideoFrames ready to pass over to WebRTC as webrtc::VideoFrames.\nWe can either pass along frames A, B and C or we can create some pseudo-frame D that hides frame A, B and C inside of it only to expose it when you request to scale it.\n\nThis requirement that we must have a frame of size \"adapted source size\" is legacy. We\u0027re not interested in the 480p frame, the only reason we care about 480p is because that is what we use as input to ReconfigureEncoder(). But the 480p value is really just derived from the rtc::VideoSinkWants, which comes from ResourceAdaptation, so with a bit of refactoring maybe we could have wired up ReconfigureEncoder() to the rtc::VideoSinkWants directly. Only reason we can\u0027t is because of VideoAdapter logic, and I don\u0027t want to touch that for the sake of scaled frames.",
      "parentUuid": "74ce1258_6148ca6a",
      "range": {
        "startLine": 49,
        "startChar": 24,
        "endLine": 49,
        "endChar": 69
      },
      "revId": "2ebc59d9aa1e82a8df055a247f8a260b5dcd5895",
      "serverId": "58829da1-049c-39fb-b951-ebdcd0984767"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "7cf350ef_650ee2ab",
        "filename": "api/video/video_sink_interface.h",
        "patchSetId": 7
      },
      "lineNbr": 49,
      "author": {
        "id": 5117
      },
      "writtenOn": "2021-02-17T14:45:44Z",
      "side": 1,
      "message": "The complication is that regardless of what webrtc has requested you must pass down the full resolution frame (because the feedback is delayed). But that frame is not that webrtc has requested, so it now doesn\u0027t cleanly align with your view of \"passing down exactly what is requested\". If you explicitly pass scaled images, you need to keep checking if they are not what you need and perform actual scaling as it\u0027s done before. Then, you need to somehow make it work with multiple scaling steps (one adaptation step in WebRtcVideoTrackSource, cropping in VideoStreamEncoder, scaling in SimulcastEncoderAdapter/libvpx_vp8_encoder).\n\nIt would be a lot of copy paste. Abstracting all these extra frames as cache of pre-scaled images is removing all this complexity. Since all this feedback is best-effort anyway, I don\u0027t think it should dictate the interface.\n\nIt\u0027s unfortunate, that we couldn\u0027t include additional frames as a member in media::VideoFrame, but in webrtc we can abstract this complexity away.",
      "parentUuid": "adbf4e2c_33c9b009",
      "range": {
        "startLine": 49,
        "startChar": 24,
        "endLine": 49,
        "endChar": 69
      },
      "revId": "2ebc59d9aa1e82a8df055a247f8a260b5dcd5895",
      "serverId": "58829da1-049c-39fb-b951-ebdcd0984767"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "3fdb88b7_371cfa88",
        "filename": "api/video/video_sink_interface.h",
        "patchSetId": 7
      },
      "lineNbr": 49,
      "author": {
        "id": 5142
      },
      "writtenOn": "2021-02-17T15:11:04Z",
      "side": 1,
      "message": "Hmm, it would be nice to avoid copy-paste...",
      "parentUuid": "7cf350ef_650ee2ab",
      "range": {
        "startLine": 49,
        "startChar": 24,
        "endLine": 49,
        "endChar": 69
      },
      "revId": "2ebc59d9aa1e82a8df055a247f8a260b5dcd5895",
      "serverId": "58829da1-049c-39fb-b951-ebdcd0984767"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "b5256eb7_72f4d362",
        "filename": "media/base/video_broadcaster.cc",
        "patchSetId": 7
      },
      "lineNbr": 87,
      "author": {
        "id": 5117
      },
      "writtenOn": "2021-02-17T13:45:00Z",
      "side": 1,
      "message": "This is UaF pitfall here. If the frame is buffered somewhere (like it does in encoder queue), |black_frame| would be destroyed.",
      "range": {
        "startLine": 87,
        "startChar": 32,
        "endLine": 87,
        "endChar": 33
      },
      "revId": "2ebc59d9aa1e82a8df055a247f8a260b5dcd5895",
      "serverId": "58829da1-049c-39fb-b951-ebdcd0984767"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "afaa4f6a_8529452a",
        "filename": "media/base/video_broadcaster.cc",
        "patchSetId": 7
      },
      "lineNbr": 87,
      "author": {
        "id": 5142
      },
      "writtenOn": "2021-02-17T14:20:36Z",
      "side": 1,
      "message": "I changed \"const VideoFrame\u0026\" to \"const std::vector\u003cconst VideoFrame*\u003e\u0026\". I would have liked to pass in \"std::vector\u003cconst VideoFrame\u0026\u003e\" but C++ does not allow vectors of refs.\n\nUnfortunately I can\u0027t pass in \"const std::vector\u003cVideoFrame\u003e\u0026\" because VideoSinkInterface\u003cT\u003e is template-instantiated with RecordableEncodedFrame which is an abstract interface, so I can\u0027t have a vector of RecordableEncodedFrame-values, it needs to be ptrs in order to point to implementations of RecordableEncodedFrame.\n\nAny suggestion if this can be made better?",
      "parentUuid": "b5256eb7_72f4d362",
      "range": {
        "startLine": 87,
        "startChar": 32,
        "endLine": 87,
        "endChar": 33
      },
      "revId": "2ebc59d9aa1e82a8df055a247f8a260b5dcd5895",
      "serverId": "58829da1-049c-39fb-b951-ebdcd0984767"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "42a1e4de_874cd1b1",
        "filename": "media/base/video_broadcaster.cc",
        "patchSetId": 7
      },
      "lineNbr": 87,
      "author": {
        "id": 5117
      },
      "writtenOn": "2021-02-17T14:45:44Z",
      "side": 1,
      "message": "You don\u0027t need all the VideoFrame metadata on all the scaled versions.\nYou can have vector of VideoFrameBuffer inside the webrtc::VideoFrame.",
      "parentUuid": "afaa4f6a_8529452a",
      "range": {
        "startLine": 87,
        "startChar": 32,
        "endLine": 87,
        "endChar": 33
      },
      "revId": "2ebc59d9aa1e82a8df055a247f8a260b5dcd5895",
      "serverId": "58829da1-049c-39fb-b951-ebdcd0984767"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "bdae040c_21b7b373",
        "filename": "video/video_stream_encoder.cc",
        "patchSetId": 7
      },
      "lineNbr": 1280,
      "author": {
        "id": 5142
      },
      "writtenOn": "2021-02-17T12:48:07Z",
      "side": 1,
      "message": "Ilya what is this update rect that is set in multiple places?\n\nI have currently kept it as-is only looking at the 0-th frame, which is the only one being encoded at the moment, but I wonder if I need to keep track of one update rect per scaled frame in the future or if we can reuse the same update rect for each frame but with a different scale factor?\n\nWhat is the update rect?",
      "revId": "2ebc59d9aa1e82a8df055a247f8a260b5dcd5895",
      "serverId": "58829da1-049c-39fb-b951-ebdcd0984767"
    },
    {
      "unresolved": false,
      "key": {
        "uuid": "d76fdeac_d2e94c28",
        "filename": "video/video_stream_encoder.cc",
        "patchSetId": 7
      },
      "lineNbr": 1280,
      "author": {
        "id": 5117
      },
      "writtenOn": "2021-02-17T13:45:00Z",
      "side": 1,
      "message": "It indicates, which part of the frame was updated since the last frame. It is set by tab capturer only currently.\n\nIt\u0027s used to detect static content and adjust encode framerate.",
      "parentUuid": "bdae040c_21b7b373",
      "revId": "2ebc59d9aa1e82a8df055a247f8a260b5dcd5895",
      "serverId": "58829da1-049c-39fb-b951-ebdcd0984767"
    }
  ]
}