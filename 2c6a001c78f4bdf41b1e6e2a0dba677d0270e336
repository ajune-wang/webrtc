{
  "comments": [
    {
      "unresolved": true,
      "key": {
        "uuid": "a188a7ab_54cb5da1",
        "filename": "/PATCHSET_LEVEL",
        "patchSetId": 29
      },
      "lineNbr": 0,
      "author": {
        "id": 8038
      },
      "writtenOn": "2023-05-03T20:02:34Z",
      "side": 1,
      "message": "I think one problem with using the SourceTracker is that it only updates when new packets are decoded, so it doesn\u0027t necessary reflect what is played out.\n\nOne suggestion is to use the audio level that is computed in ChannelReceive instead that measures the audio samples that are played out. GetSpeechOutputLevelFullRange (https://source.chromium.org/chromium/chromium/src/+/refs/heads/main:third_party/webrtc/audio/channel_receive.h;l\u003d107;drc\u003de0e0d24aaa54727dc0a8bc4b159ccdf80d3f5d8d) has some smoothing built in that may or may not be desirable.\n\nWe could calculate the energy using only the frame directly otherwise. This is already done in the mixer so it would be nice to avoid doing it multiple times: https://source.chromium.org/chromium/chromium/src/+/refs/heads/main:third_party/webrtc/modules/audio_mixer/audio_mixer_impl.cc;l\u003d53;drc\u003de0e0d24aaa54727dc0a8bc4b159ccdf80d3f5d8d",
      "revId": "2c6a001c78f4bdf41b1e6e2a0dba677d0270e336",
      "serverId": "58829da1-049c-39fb-b951-ebdcd0984767"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "e955e854_893fb62b",
        "filename": "/PATCHSET_LEVEL",
        "patchSetId": 29
      },
      "lineNbr": 0,
      "author": {
        "id": 5508
      },
      "writtenOn": "2023-05-05T13:42:08Z",
      "side": 1,
      "message": "`[SourceTracker] only updates when new packets are decoded`\n- Actually ST does get updated even when neteq is not in the picture and playout is not active:\n\nhttps://source.chromium.org/chromium/chromium/src/+/refs/heads/main:third_party/webrtc/audio/channel_receive.cc;l\u003d332\n\nI did consider `GetSpeechOutputLevelFullRange()` too but beyond the playout aspect of neteq there are more reasons why SourceTracker is a good fit.\n\nhta@ and discussed this particular case too btw and here are some of our reasonings that\u0027s hopefully useful:\n\nThe muted state of a remote _source_ (notably, not _track_) conceptually represents the source state before playout. One way to think of it is that \u0027muted\u0027 represents state at the input of a source rather than the output. Output being what\u0027s then feeding playout. E.g. with a microphone, the mute state reflects the OS mute state (or hw) of the mic, which is state that the application does not control (at least not via webrtc). The `enabled` property on the other hand is what the application can use to apply its own control to mute the output of the audio track.\n\nSimilarly, for a remote track, the state that\u0027s outside of the application\u0027s control, is owned by the sender. The mute state from the sender, should ideally match with what the receiver reads it as. `GetSpeechOutputLevelFullRange()` can report non-0 values for a fully muted remote sources, which is because of a local source (neteq) can affect the level when playout is active and generate noise (which technically is an implementation detail of webrtc). Whether or not that\u0027s a bug doesn\u0027t matter for this case, but it\u0027s important to note since if we were to check the state at that point, it could make a receiver\u0027s mute state be different than sender\u0027s for exactly the same audio packets.\n\nAnother aspect I was thinking about that\u0027s maybe good to be aware of, but is more about performance, is that GetSpeechOutputLevelFullRange() currently is prone to contention between the audio thread and network thread. This has been the case for as long as I can remember, but I\u0027d of course like to not add _more_ opportunities for contention. SourceTracker won\u0027t cause that.\n\nBeyond that, taking into account other architectural changes that are currently in-flight (especially as it relates to Chrome), some of the audio source/track APIs/states are currently tied to the \u0027worker\u0027 thread. They, along with getCSRCs, need to migrate from the worker to the signaling thread. That\u0027s because the worker and network threads are becoming one and the same and we don\u0027t want to block the network thread. Once we do that, it will further allow us to improve performance in Chrome by allowing this data to live on the js thread and even be queryable without involving the signaling thread (as is done for some properties already). The data in SourceTracker is already being managed in a lock-free way, which helps.\n\nOne last thing to consider is if we want to open up ways for applications to bring their own jitter buffer implementations, then having this part of the wire-up for an audio source to be connected to the source before neteq (rather than dependent on it), could make things architecturally easier down the line.",
      "parentUuid": "a188a7ab_54cb5da1",
      "revId": "2c6a001c78f4bdf41b1e6e2a0dba677d0270e336",
      "serverId": "58829da1-049c-39fb-b951-ebdcd0984767"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "2f185fa5_0e4aac72",
        "filename": "/PATCHSET_LEVEL",
        "patchSetId": 29
      },
      "lineNbr": 0,
      "author": {
        "id": 8038
      },
      "writtenOn": "2023-05-05T16:06:44Z",
      "side": 1,
      "message": "Thanks, I think what you are saying around reflecting the remote \"source\" state makes sense. This is how RTCRtpSynchronizationSource is implemented for example.\n\nReading the spec here: https://www.w3.org/TR/webrtc/#mediastreamtrack-network-use\n\nAccording to this, any incoming packet should \"unmute\" the track and muting is triggered by receiving RTCP_BYE or timeout in absence of any packets.\n\nMaybe the spec is designed for video and not the audio use case where muting is typically done by setting `track.enabled \u003d false` instead of stop sending completely. Do we need to update the spec so that it makes more sense for audio? Or are there other parts of the spec that I have missed?\n\nAnother thing to consider is what to do when the sender doesn\u0027t use the audio level header extension?",
      "parentUuid": "e955e854_893fb62b",
      "revId": "2c6a001c78f4bdf41b1e6e2a0dba677d0270e336",
      "serverId": "58829da1-049c-39fb-b951-ebdcd0984767"
    },
    {
      "unresolved": false,
      "key": {
        "uuid": "8d3db8cb_09ab5bbf",
        "filename": "/PATCHSET_LEVEL",
        "patchSetId": 29
      },
      "lineNbr": 0,
      "author": {
        "id": 8038
      },
      "writtenOn": "2023-05-05T16:06:44Z",
      "side": 1,
      "message": "Adding Harald to our discussion around the spec.",
      "revId": "2c6a001c78f4bdf41b1e6e2a0dba677d0270e336",
      "serverId": "58829da1-049c-39fb-b951-ebdcd0984767"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "11240615_d97b7e23",
        "filename": "pc/remote_audio_source.cc",
        "patchSetId": 29
      },
      "lineNbr": 33,
      "author": {
        "id": 8038
      },
      "writtenOn": "2023-05-05T16:06:44Z",
      "side": 1,
      "message": "This feels out of place here. This should be handled in the source tracker or before it. If the receive stream is active, then updates to the source tracker will be in-order (i.e. this is redundant). In the other case, https://www.w3.org/TR/webrtc/#dom-rtcrtpcontributingsource says that packets must be processed in order, so the check should probably be in the source tracker.",
      "range": {
        "startLine": 33,
        "startChar": 0,
        "endLine": 33,
        "endChar": 76
      },
      "revId": "2c6a001c78f4bdf41b1e6e2a0dba677d0270e336",
      "serverId": "58829da1-049c-39fb-b951-ebdcd0984767"
    }
  ]
}