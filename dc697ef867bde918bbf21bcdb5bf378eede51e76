{
  "comments": [
    {
      "key": {
        "uuid": "16d94505_19a069e9",
        "filename": "modules/audio_processing/agc2/rnn_vad/rnn.cc",
        "patchSetId": 2
      },
      "lineNbr": 67,
      "author": {
        "id": 5607
      },
      "writtenOn": "2018-04-24T12:19:57Z",
      "side": 1,
      "message": "Isn\u0027t a DCHECK good enough here and below, since these are constants?",
      "range": {
        "startLine": 67,
        "startChar": 2,
        "endLine": 67,
        "endChar": 14
      },
      "revId": "dc697ef867bde918bbf21bcdb5bf378eede51e76",
      "serverId": "58829da1-049c-39fb-b951-ebdcd0984767",
      "unresolved": true
    },
    {
      "key": {
        "uuid": "5cfdbe9e_c948c433",
        "filename": "modules/audio_processing/agc2/rnn_vad/rnn.cc",
        "patchSetId": 2
      },
      "lineNbr": 67,
      "author": {
        "id": 5122
      },
      "writtenOn": "2018-04-24T15:33:43Z",
      "side": 1,
      "message": "Done",
      "parentUuid": "16d94505_19a069e9",
      "range": {
        "startLine": 67,
        "startChar": 2,
        "endLine": 67,
        "endChar": 14
      },
      "revId": "dc697ef867bde918bbf21bcdb5bf378eede51e76",
      "serverId": "58829da1-049c-39fb-b951-ebdcd0984767",
      "unresolved": false
    },
    {
      "key": {
        "uuid": "60db3700_ab4febf6",
        "filename": "modules/audio_processing/agc2/rnn_vad/rnn.cc",
        "patchSetId": 2
      },
      "lineNbr": 88,
      "author": {
        "id": 5607
      },
      "writtenOn": "2018-04-24T12:19:57Z",
      "side": 1,
      "message": "I think this loop would be more efficient if weights_ was transposed, then we would read the values in adjacent memory locations in this loop (instead of making big jumps). Now we are making big jumps, which causes cache misses. The same applies to various loops below.",
      "range": {
        "startLine": 88,
        "startChar": 31,
        "endLine": 88,
        "endChar": 61
      },
      "revId": "dc697ef867bde918bbf21bcdb5bf378eede51e76",
      "serverId": "58829da1-049c-39fb-b951-ebdcd0984767",
      "unresolved": true
    },
    {
      "key": {
        "uuid": "83751122_e3735dcf",
        "filename": "modules/audio_processing/agc2/rnn_vad/rnn.cc",
        "patchSetId": 2
      },
      "lineNbr": 88,
      "author": {
        "id": 5122
      },
      "writtenOn": "2018-04-24T15:33:43Z",
      "side": 1,
      "message": "Thanks for this suggestion. To address this I have to reshape weights_ in //third_party/rnnoise first. Note however that this network is relatively small, with the largest fully connected layer with 42x24\u003d1008 weights. Each weight is a byte, hence the whole matrix gets about 1k. For an L1 cache of 32kB, we may expect that the whole matrix is loaded.\n\nThe change you suggest would require a benchmark. For now, I would prefer to stick to the reference implementation and when time allows we investigate which structure of the network weights leads to the best performance across-platforms. I added a TODO for that (similarly as done elsewhere in this VAD).",
      "parentUuid": "60db3700_ab4febf6",
      "range": {
        "startLine": 88,
        "startChar": 31,
        "endLine": 88,
        "endChar": 61
      },
      "revId": "dc697ef867bde918bbf21bcdb5bf378eede51e76",
      "serverId": "58829da1-049c-39fb-b951-ebdcd0984767",
      "unresolved": false
    },
    {
      "key": {
        "uuid": "3f646a6b_9027b710",
        "filename": "modules/audio_processing/agc2/rnn_vad/rnn.cc",
        "patchSetId": 2
      },
      "lineNbr": 88,
      "author": {
        "id": 5607
      },
      "writtenOn": "2018-04-25T09:20:17Z",
      "side": 1,
      "message": "Ok, I guess you\u0027re right that it may not make a huge difference for such small matrices.\nBy the way, I suspect that the implicit int8_t to float conversion in this loop (for the weights) may not be super efficient, but it\u0027s fine to keep it like this for now.",
      "parentUuid": "83751122_e3735dcf",
      "range": {
        "startLine": 88,
        "startChar": 31,
        "endLine": 88,
        "endChar": 61
      },
      "revId": "dc697ef867bde918bbf21bcdb5bf378eede51e76",
      "serverId": "58829da1-049c-39fb-b951-ebdcd0984767",
      "unresolved": false
    },
    {
      "key": {
        "uuid": "1584659e_b882e9bb",
        "filename": "modules/audio_processing/agc2/rnn_vad/rnn.cc",
        "patchSetId": 2
      },
      "lineNbr": 88,
      "author": {
        "id": 5122
      },
      "writtenOn": "2018-04-25T15:56:17Z",
      "side": 1,
      "message": "Good point. I was also wondering if storing the weights as floats helps.\nI should check what the compiler does here, but I guess they\u0027re left as int8, type that was chosen to reduce the binary size.",
      "parentUuid": "3f646a6b_9027b710",
      "range": {
        "startLine": 88,
        "startChar": 31,
        "endLine": 88,
        "endChar": 61
      },
      "revId": "dc697ef867bde918bbf21bcdb5bf378eede51e76",
      "serverId": "58829da1-049c-39fb-b951-ebdcd0984767",
      "unresolved": false
    },
    {
      "key": {
        "uuid": "bfee0780_1b4eb608",
        "filename": "modules/audio_processing/agc2/rnn_vad/rnn.h",
        "patchSetId": 2
      },
      "lineNbr": 42,
      "author": {
        "id": 5607
      },
      "writtenOn": "2018-04-24T12:19:57Z",
      "side": 1,
      "message": "I think old-fashioned function pointers are more efficient than std::function. You could consider switching to those, since I don\u0027t think you need any of the special features of std::function in this case. (same for GratedRecurrentLayer)",
      "range": {
        "startLine": 42,
        "startChar": 22,
        "endLine": 42,
        "endChar": 69
      },
      "revId": "dc697ef867bde918bbf21bcdb5bf378eede51e76",
      "serverId": "58829da1-049c-39fb-b951-ebdcd0984767",
      "unresolved": true
    },
    {
      "key": {
        "uuid": "5b897438_eecfae6d",
        "filename": "modules/audio_processing/agc2/rnn_vad/rnn.h",
        "patchSetId": 2
      },
      "lineNbr": 42,
      "author": {
        "id": 5122
      },
      "writtenOn": "2018-04-24T15:33:43Z",
      "side": 1,
      "message": "Done",
      "parentUuid": "bfee0780_1b4eb608",
      "range": {
        "startLine": 42,
        "startChar": 22,
        "endLine": 42,
        "endChar": 69
      },
      "revId": "dc697ef867bde918bbf21bcdb5bf378eede51e76",
      "serverId": "58829da1-049c-39fb-b951-ebdcd0984767",
      "unresolved": false
    },
    {
      "key": {
        "uuid": "859280c8_81acc018",
        "filename": "modules/audio_processing/agc2/rnn_vad/rnn.h",
        "patchSetId": 2
      },
      "lineNbr": 44,
      "author": {
        "id": 5607
      },
      "writtenOn": "2018-04-24T12:19:57Z",
      "side": 1,
      "message": "There is a macro to do this: RTC_DISALLOW_COPY_AND_ASSIGN, so I suggest to use that instead (same for classes below).",
      "range": {
        "startLine": 43,
        "startChar": 0,
        "endLine": 44,
        "endChar": 70
      },
      "revId": "dc697ef867bde918bbf21bcdb5bf378eede51e76",
      "serverId": "58829da1-049c-39fb-b951-ebdcd0984767",
      "unresolved": true
    },
    {
      "key": {
        "uuid": "6c6cad41_31617cbf",
        "filename": "modules/audio_processing/agc2/rnn_vad/rnn.h",
        "patchSetId": 2
      },
      "lineNbr": 44,
      "author": {
        "id": 5122
      },
      "writtenOn": "2018-04-24T15:33:43Z",
      "side": 1,
      "message": "Ack",
      "parentUuid": "859280c8_81acc018",
      "range": {
        "startLine": 43,
        "startChar": 0,
        "endLine": 44,
        "endChar": 70
      },
      "revId": "dc697ef867bde918bbf21bcdb5bf378eede51e76",
      "serverId": "58829da1-049c-39fb-b951-ebdcd0984767",
      "unresolved": false
    },
    {
      "key": {
        "uuid": "36cefdec_bf29e3c3",
        "filename": "modules/audio_processing/agc2/rnn_vad/rnn.h",
        "patchSetId": 2
      },
      "lineNbr": 57,
      "author": {
        "id": 5607
      },
      "writtenOn": "2018-04-24T12:19:57Z",
      "side": 1,
      "message": "This can be const as well, right? (same for GratedRecurrentLayer)",
      "range": {
        "startLine": 57,
        "startChar": 2,
        "endLine": 57,
        "endChar": 29
      },
      "revId": "dc697ef867bde918bbf21bcdb5bf378eede51e76",
      "serverId": "58829da1-049c-39fb-b951-ebdcd0984767",
      "unresolved": true
    },
    {
      "key": {
        "uuid": "ae3959cc_0fd3eb65",
        "filename": "modules/audio_processing/agc2/rnn_vad/rnn.h",
        "patchSetId": 2
      },
      "lineNbr": 57,
      "author": {
        "id": 5122
      },
      "writtenOn": "2018-04-24T15:33:43Z",
      "side": 1,
      "message": "Done",
      "parentUuid": "36cefdec_bf29e3c3",
      "range": {
        "startLine": 57,
        "startChar": 2,
        "endLine": 57,
        "endChar": 29
      },
      "revId": "dc697ef867bde918bbf21bcdb5bf378eede51e76",
      "serverId": "58829da1-049c-39fb-b951-ebdcd0984767",
      "unresolved": false
    },
    {
      "key": {
        "uuid": "ada3ab5e_3c993924",
        "filename": "modules/audio_processing/agc2/rnn_vad/rnn.h",
        "patchSetId": 2
      },
      "lineNbr": 59,
      "author": {
        "id": 5607
      },
      "writtenOn": "2018-04-24T12:19:57Z",
      "side": 1,
      "message": "I\u0027m not sure I understand how over-allocation is more efficient. Can you explain?",
      "range": {
        "startLine": 59,
        "startChar": 4,
        "endLine": 59,
        "endChar": 53
      },
      "revId": "dc697ef867bde918bbf21bcdb5bf378eede51e76",
      "serverId": "58829da1-049c-39fb-b951-ebdcd0984767",
      "unresolved": true
    },
    {
      "key": {
        "uuid": "0405bd09_bc34cdc7",
        "filename": "modules/audio_processing/agc2/rnn_vad/rnn.h",
        "patchSetId": 2
      },
      "lineNbr": 59,
      "author": {
        "id": 5122
      },
      "writtenOn": "2018-04-24T15:33:43Z",
      "side": 1,
      "message": "Sorry, I want to avoid dynamic allocation. Comment fixed.",
      "parentUuid": "ada3ab5e_3c993924",
      "range": {
        "startLine": 59,
        "startChar": 4,
        "endLine": 59,
        "endChar": 53
      },
      "revId": "dc697ef867bde918bbf21bcdb5bf378eede51e76",
      "serverId": "58829da1-049c-39fb-b951-ebdcd0984767",
      "unresolved": false
    },
    {
      "key": {
        "uuid": "3d7a5314_886856ae",
        "filename": "modules/audio_processing/agc2/rnn_vad/rnn.h",
        "patchSetId": 2
      },
      "lineNbr": 59,
      "author": {
        "id": 5607
      },
      "writtenOn": "2018-04-25T09:20:17Z",
      "side": 1,
      "message": "I guess it\u0027s fine to keep it like this, but another option would be to use a template argument to set the size of the array, then you would not need to over-allocate. Also possible is to use a vector and set the size immediately (i.e. std::vector\u003cfloat\u003e output_ \u003d std::vector\u003cfloat\u003e(kFullyConnectedLayersMaxUnits); )",
      "parentUuid": "0405bd09_bc34cdc7",
      "range": {
        "startLine": 59,
        "startChar": 4,
        "endLine": 59,
        "endChar": 53
      },
      "revId": "dc697ef867bde918bbf21bcdb5bf378eede51e76",
      "serverId": "58829da1-049c-39fb-b951-ebdcd0984767",
      "unresolved": false
    },
    {
      "key": {
        "uuid": "7c4af925_6b96a4a9",
        "filename": "modules/audio_processing/agc2/rnn_vad/rnn.h",
        "patchSetId": 2
      },
      "lineNbr": 59,
      "author": {
        "id": 5122
      },
      "writtenOn": "2018-04-25T15:56:17Z",
      "side": 1,
      "message": "Right, templates are another option although for the FC layer it would lead to binary size increase. Since the network is small and the over-allocation is only used for the output layer, I would avoid templates.",
      "parentUuid": "3d7a5314_886856ae",
      "range": {
        "startLine": 59,
        "startChar": 4,
        "endLine": 59,
        "endChar": 53
      },
      "revId": "dc697ef867bde918bbf21bcdb5bf378eede51e76",
      "serverId": "58829da1-049c-39fb-b951-ebdcd0984767",
      "unresolved": false
    }
  ]
}