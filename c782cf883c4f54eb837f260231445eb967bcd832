{
  "comments": [
    {
      "unresolved": true,
      "key": {
        "uuid": "9397eacd_8d876ed7",
        "filename": "/PATCHSET_LEVEL",
        "patchSetId": 19
      },
      "lineNbr": 0,
      "author": {
        "id": 17969
      },
      "writtenOn": "2022-05-25T04:58:11Z",
      "side": 1,
      "message": "Added some questions.",
      "revId": "c782cf883c4f54eb837f260231445eb967bcd832",
      "serverId": "58829da1-049c-39fb-b951-ebdcd0984767"
    },
    {
      "unresolved": false,
      "key": {
        "uuid": "20dc2132_ec0555f0",
        "filename": "/PATCHSET_LEVEL",
        "patchSetId": 19
      },
      "lineNbr": 0,
      "author": {
        "id": 17969
      },
      "writtenOn": "2022-05-25T05:30:06Z",
      "side": 1,
      "message": "Done",
      "parentUuid": "9397eacd_8d876ed7",
      "revId": "c782cf883c4f54eb837f260231445eb967bcd832",
      "serverId": "58829da1-049c-39fb-b951-ebdcd0984767"
    },
    {
      "unresolved": false,
      "key": {
        "uuid": "3a32a9c7_71048c52",
        "filename": "/PATCHSET_LEVEL",
        "patchSetId": 19
      },
      "lineNbr": 0,
      "author": {
        "id": 17969
      },
      "writtenOn": "2022-05-25T07:07:41Z",
      "side": 1,
      "message": "Maybe also update this place for AVSync, which currently uses filtered buffer level.",
      "revId": "c782cf883c4f54eb837f260231445eb967bcd832",
      "serverId": "58829da1-049c-39fb-b951-ebdcd0984767"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "87c885ad_fb95a593",
        "filename": "modules/audio_coding/neteq/decision_logic.cc",
        "patchSetId": 19
      },
      "lineNbr": 332,
      "author": {
        "id": 14634
      },
      "writtenOn": "2022-05-19T18:52:53Z",
      "side": 1,
      "message": "not totally related, but just seeing it again here - would be interesting, rather than having a \u0027fast accelerate vs accelerate\u0027, to do this generically - return a value based on the difference between playout delay vs target delay (and in future, possibly based on % chance underrun as well, or even how long we\u0027ve been in this state, etc) - and use this value for the correlation_threshold in accelerate [1]/preemptive expand. \nSo we become more accepting of what we\u0027ll time stretch as the difference gets larger.\n\n[1] https://source.chromium.org/chromium/chromium/src/+/main:third_party/webrtc/modules/audio_coding/neteq/accelerate.cc;l\u003d56;drc\u003d8a609a649e36c8099c6801d41aca1ec3b0b3af73;bpv\u003d0;bpt\u003d1",
      "revId": "c782cf883c4f54eb837f260231445eb967bcd832",
      "serverId": "58829da1-049c-39fb-b951-ebdcd0984767"
    },
    {
      "unresolved": false,
      "key": {
        "uuid": "b606d72a_9a2a4925",
        "filename": "modules/audio_coding/neteq/decision_logic.cc",
        "patchSetId": 19
      },
      "lineNbr": 332,
      "author": {
        "id": 8038
      },
      "writtenOn": "2022-05-24T20:08:57Z",
      "side": 1,
      "message": "Would definitely be interesting to have a dynamic accelerate/decelerate rate.",
      "parentUuid": "87c885ad_fb95a593",
      "revId": "c782cf883c4f54eb837f260231445eb967bcd832",
      "serverId": "58829da1-049c-39fb-b951-ebdcd0984767"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "263f7923_cbb4de65",
        "filename": "modules/audio_coding/neteq/decision_logic.cc",
        "patchSetId": 19
      },
      "lineNbr": 447,
      "author": {
        "id": 17969
      },
      "writtenOn": "2022-05-25T06:05:25Z",
      "side": 1,
      "message": "Any special consideration to do expand instead of CNG? Quality should be the same, but it weakens signals of expand/plc/plccng.",
      "revId": "c782cf883c4f54eb837f260231445eb967bcd832",
      "serverId": "58829da1-049c-39fb-b951-ebdcd0984767"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "20d6cf59_44b04a91",
        "filename": "modules/audio_coding/neteq/decision_logic.cc",
        "patchSetId": 19
      },
      "lineNbr": 474,
      "author": {
        "id": 14634
      },
      "writtenOn": "2022-05-19T18:52:53Z",
      "side": 1,
      "message": "it would be cool in the future to have these probability based - i.e. \"theres a \u003e x% chance we will underrun\"",
      "revId": "c782cf883c4f54eb837f260231445eb967bcd832",
      "serverId": "58829da1-049c-39fb-b951-ebdcd0984767"
    },
    {
      "unresolved": false,
      "key": {
        "uuid": "82cef225_fd0a5d93",
        "filename": "modules/audio_coding/neteq/decision_logic.cc",
        "patchSetId": 19
      },
      "lineNbr": 474,
      "author": {
        "id": 8038
      },
      "writtenOn": "2022-05-24T20:08:57Z",
      "side": 1,
      "message": "Yes this 75% is a bit arbitrary. The idea is that we expect to see more delay variation when the target delay is high, so we accept a larger diff compared to the target in this case (that made sense when using the buffer level filter but not sure if it does with the new, \"more stable\", delay estimation).\n\nIn practice, we rarely do preemptive expand. We usually increase the target delay after an underrun and in that case the playout delay is most likely already high (due to the delayed packet arrival).",
      "parentUuid": "20d6cf59_44b04a91",
      "revId": "c782cf883c4f54eb837f260231445eb967bcd832",
      "serverId": "58829da1-049c-39fb-b951-ebdcd0984767"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "bf833681_5cae67b9",
        "filename": "modules/audio_coding/neteq/decision_logic.cc",
        "patchSetId": 19
      },
      "lineNbr": 474,
      "author": {
        "id": 17969
      },
      "writtenOn": "2022-05-25T04:58:11Z",
      "side": 1,
      "message": "Let\u0027s have two wild assumptions: 1. target level doesn\u0027t change; 2. delay manager gives us perfect target level which will be larger than all future jitters by a just small margin. \n\nWith above conditions, do we really need any preemptive expand at all to prevent underrun? In other words, if we have perfect jitter estimation, then we don\u0027t ever need preemptive expand unless target level changes. \n\nThis CL greatly reduces preemptive expands, which would\u0027ve happened with previous SpanSamples calculation. Is this intentional? : )\n\nCan we expect zero preemptive expand when target level doesn\u0027t change? Any caveat?",
      "parentUuid": "82cef225_fd0a5d93",
      "revId": "c782cf883c4f54eb837f260231445eb967bcd832",
      "serverId": "58829da1-049c-39fb-b951-ebdcd0984767"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "d20a774c_23d8761f",
        "filename": "modules/audio_coding/neteq/decision_logic.cc",
        "patchSetId": 19
      },
      "lineNbr": 474,
      "author": {
        "id": 17969
      },
      "writtenOn": "2022-05-25T05:30:06Z",
      "side": 1,
      "message": "Besides target level changes, a permanent increase in network travel time will also causes preemptive expand.",
      "parentUuid": "bf833681_5cae67b9",
      "revId": "c782cf883c4f54eb837f260231445eb967bcd832",
      "serverId": "58829da1-049c-39fb-b951-ebdcd0984767"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "ca4afd72_e9af3090",
        "filename": "modules/audio_coding/neteq/decision_logic.cc",
        "patchSetId": 19
      },
      "lineNbr": 481,
      "author": {
        "id": 17969
      },
      "writtenOn": "2022-05-25T04:58:11Z",
      "side": 1,
      "message": "Curious under what cases TargetLevelMs() isn\u0027t enough such that we need to use GetMaxDelayMs()?",
      "revId": "c782cf883c4f54eb837f260231445eb967bcd832",
      "serverId": "58829da1-049c-39fb-b951-ebdcd0984767"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "f3fb8b54_597bce5a",
        "filename": "modules/audio_coding/neteq/decision_logic.cc",
        "patchSetId": 19
      },
      "lineNbr": 481,
      "author": {
        "id": 17969
      },
      "writtenOn": "2022-05-25T05:30:06Z",
      "side": 1,
      "message": "NVM, saw the CL summary.",
      "parentUuid": "ca4afd72_e9af3090",
      "revId": "c782cf883c4f54eb837f260231445eb967bcd832",
      "serverId": "58829da1-049c-39fb-b951-ebdcd0984767"
    },
    {
      "unresolved": false,
      "key": {
        "uuid": "050f6b3b_bc8bd616",
        "filename": "modules/audio_coding/neteq/decision_logic.cc",
        "patchSetId": 19
      },
      "lineNbr": 481,
      "author": {
        "id": 17969
      },
      "writtenOn": "2022-05-25T06:05:25Z",
      "side": 1,
      "message": "Done",
      "parentUuid": "f3fb8b54_597bce5a",
      "revId": "c782cf883c4f54eb837f260231445eb967bcd832",
      "serverId": "58829da1-049c-39fb-b951-ebdcd0984767"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "7c9a49b1_7b2d017c",
        "filename": "modules/audio_coding/neteq/packet_arrival_history.cc",
        "patchSetId": 19
      },
      "lineNbr": 23,
      "author": {
        "id": 14634
      },
      "writtenOn": "2022-05-19T18:52:53Z",
      "side": 1,
      "message": "nit - probably not too important, but if the additional delays were a wide guassian (a high std), it might make more sense to use something like the p90 (p50? mean?) fastest arriving or some other smoothing, so a highly varying min arrival wouldn\u0027t cause big changes as the window slides (a p99.9 fast packet vs a p95). \nBut also, I doubt many networks would really look like that, especially with a 2s window, unless you maybe had some very specific variable cross traffic? But tests[1] can :) \n\n[1] https://source.chromium.org/chromium/chromium/src/+/main:third_party/webrtc/call/simulated_network.cc;l\u003d228-229;drc\u003d8a609a649e36c8099c6801d41aca1ec3b0b3af73;bpv\u003d0;bpt\u003d1",
      "revId": "c782cf883c4f54eb837f260231445eb967bcd832",
      "serverId": "58829da1-049c-39fb-b951-ebdcd0984767"
    },
    {
      "unresolved": false,
      "key": {
        "uuid": "1acefd2d_0421e5da",
        "filename": "modules/audio_coding/neteq/packet_arrival_history.cc",
        "patchSetId": 19
      },
      "lineNbr": 23,
      "author": {
        "id": 8038
      },
      "writtenOn": "2022-05-24T20:08:57Z",
      "side": 1,
      "message": "The idea is that the large window size should take care of this. I guess something like you describe could happen in networks with large bloated buffers. Not sure if the behavior would be better/worse with this change :)",
      "parentUuid": "7c9a49b1_7b2d017c",
      "revId": "c782cf883c4f54eb837f260231445eb967bcd832",
      "serverId": "58829da1-049c-39fb-b951-ebdcd0984767"
    }
  ]
}